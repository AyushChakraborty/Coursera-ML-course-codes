{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here the feature values are not scaled/normalised hence it needs to be. Here we use a keras normalisation layer, earler we applied tf.keras.layers.Dense to code a single\n",
    "#layer, but for normalisation we use the tf.keras.layers.Normalisation layer which is not actually a layer involved in the architechture of the NN, it is implemented as follows\n",
    "# norm_layer = tf.keras.layers.Normalisation(axis=-1)\n",
    "# norm_layer.adapt(X)   needed so that it learns the mean and variance of each of the features of the feature matrix\n",
    "# X_norm = norm_layer(X)  #normalised feature matrix obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.tile(X, (shape freq))\n",
    "X = np.array([[1, 2], [3,4]])\n",
    "X_t = np.tile(X, (4, 1))   #used for repeating certain elements in a array\n",
    "print(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementing forward prop in NN generally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense(ai_n, W, b):   #coding a single layer, similar to tf.kears.layers.Dense() routine\n",
    "  a_out = np.zeros(W.shape[1])\n",
    "  for i in range(W.shape[1]):\n",
    "    w = W[:, i]\n",
    "    z = np.dot(w, ai_n) + b[i]\n",
    "    a_out[i] += (1/(1+np.exp(-z)))\n",
    "  return a_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential(x, W1, W2, b1, b2):    #similar to tf.keras.Sequential() routine\n",
    "  a1 = dense(x, W1, b1)\n",
    "  a2 = dense(a1, W2, b2)\n",
    "  return a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#then assuming that the weights are initialised after training (again, for this lab and the prev ones we are only focusing on forward prop)\n",
    "\n",
    "def predict(X, W1, W2, b1, b2): #similar to model.predict() routine\n",
    "  m = X.shape[0]\n",
    "  p = np.zeros((m,1))\n",
    "\n",
    "  for i in range(m):\n",
    "    p[i, 0] = sequential(X[i], W1, W2, b1, b2)\n",
    "\n",
    "  return p"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
