{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COLLABORATIVE FILTERING BASED RECOMMENDER SYSTEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recommender systems are just an egs of multivariate linear regression where multiple labels for the same sample \n",
    "#exist, in this case the multiple labels are the ratings given by diff users for the movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.loadtxt('C:\\\\Users\\\\Lenovo\\\\OneDrive\\\\Desktop\\\\coursera_ml\\\\small_movies_X.csv', delimiter=',')\n",
    "Y = np.loadtxt('C:\\\\Users\\\\Lenovo\\\\OneDrive\\\\Desktop\\\\coursera_ml\\\\small_movies_Y.csv', delimiter=',')\n",
    "W = np.loadtxt('C:\\\\Users\\\\Lenovo\\\\OneDrive\\\\Desktop\\\\coursera_ml\\\\small_movies_W.csv', delimiter=',')\n",
    "R = np.loadtxt('C:\\\\Users\\\\Lenovo\\\\OneDrive\\\\Desktop\\\\coursera_ml\\\\small_movies_R.csv', delimiter=',')\n",
    "B = np.loadtxt('C:\\\\Users\\\\Lenovo\\\\OneDrive\\\\Desktop\\\\coursera_ml\\\\small_movies_b.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of features:  10\n",
      "no of movies:  4778\n",
      "no of users:  443\n"
     ]
    }
   ],
   "source": [
    "n = X.shape[1]\n",
    "nm = X.shape[0]\n",
    "nu = W.shape[0]\n",
    "\n",
    "print('no of features: ', n)\n",
    "print('no of movies: ', nm)\n",
    "print('no of users: ', nu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R shape: : (4778, 443)\n",
      "X shape:  (4778, 10)\n",
      "Y shape:  (4778, 443)\n",
      "W shape:  (443, 10)\n",
      "B shape:  (443,)\n"
     ]
    }
   ],
   "source": [
    "print(\"R shape: :\", R.shape)\n",
    "print(\"X shape: \", X.shape)\n",
    "print(\"Y shape: \", Y.shape)\n",
    "print(\"W shape: \", W.shape)\n",
    "print(\"B shape: \", B.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X: feature matrix of order (nm, n)\n",
    "#Y: ratings matrix(lables matrix) of order (nm, nu)\n",
    "#W: weight matrix of order (nu, n)\n",
    "#B: bias vector reprsented in a matrix form of order (1, nu)\n",
    "#R: check matrix which gives info if a user j has rated a movie i and its the case if that elements value is 1, of \n",
    "#order (nm, nu) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only Y, R needed to start collaborative filtering algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cost func for collaborative filtering\n",
    "def cofi_cost_func(X, Y, W, B, R, lambda_):\n",
    "    \"\"\"\n",
    "    Returns the cost for the content-based filtering\n",
    "    Vectorized for speed, using tf not numpy so as to make it compatible with the custom training loop\n",
    "\n",
    "    Args:\n",
    "      X (ndarray (num_movies,num_features)): matrix of item features\n",
    "      W (ndarray (num_users,num_features)) : matrix of user parameters\n",
    "      B (ndarray (1, num_users)            : vector of user parameters\n",
    "      Y (ndarray (num_movies,num_users)    : matrix of user ratings of movies\n",
    "      R (ndarray (num_movies,num_users)    : matrix, where R(i, j) = 1 if the i-th movies was rated by the j-th user\n",
    "      lambda_ (float): regularization parameter\n",
    "      \n",
    "    Returns:\n",
    "      J (float) : Cost\n",
    "    \"\"\"\n",
    "\n",
    "    J = 0\n",
    "\n",
    "    J += ((tf.reduce_sum(((tf.linalg.matmul(X, tf.transpose(W)) + B - Y)*R)**2)/2) + (lambda_/2)*(tf.reduce_sum(W**2) + tf.reduce_sum(X**2)))\n",
    "\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom training loop\n",
    "def training_loop(X, Y, W, B, R, lambda_, iterations, optimizer):\n",
    "    \"\"\"\n",
    "    Returns trained W, B, X for the recommender system\n",
    "    \n",
    "    Args:\n",
    "      X (ndarray (num_movies,num_features)): initial matrix of item features\n",
    "      W (ndarray (num_users,num_features)) : initial matrix of user parameters\n",
    "      B (ndarray (1, num_users)            : inintial vector of user parameters\n",
    "      Y (ndarray (num_movies,num_users)    : matrix of user ratings of movies\n",
    "      R (ndarray (num_movies,num_users)    : matrix, where R(i, j) = 1 if the i-th movies was rated by the j-th user\n",
    "      lambda_ (float): regularization parameter\n",
    "      iterations (int): number of epochs\n",
    "      optimizer (tf.keras.Adam() instance): instance of Adam optimizer\n",
    "\n",
    "    Returns:\n",
    "      X (ndarray (num_movies,num_features)): trained matrix of item features\n",
    "      W (ndarray (num_users,num_features)) : trained matrix of user parameters\n",
    "      B (ndarray (1, num_users)            : trained vector of user parameters\n",
    "      \n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(iterations):   #this is using batch gradient descent with variable leanring rate since the gradients\n",
    "        #all have the sigma notation which indicates that all the training samples are considered for an updation, so \n",
    "        #each iteration can also be considered as an epoch since in one iteration the entire dataset has been passed\n",
    "        #through\n",
    "        with tf.GradientTape() as tape:\n",
    "            cost = cofi_cost_func(X, Y, W, B, R, lambda_)\n",
    "        \n",
    "        grads = tape.gradient(cost, [X, W, B])\n",
    "        optimizer.apply_gradients(zip(grads, [X, W, B]))   #adam optimizer will be used \n",
    "\n",
    "        if i%20==0:\n",
    "            print(f\"epoch: {i+1}, cost: {cost}\")\n",
    "    \n",
    "    return X, W, B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean normalisation of Y   \n",
    "def mean_norm(Y, R):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        Y (ndarray (num_movies,num_users)    : matrix of user ratings of movies\n",
    "        R (ndarray (num_movies,num_users)    : matrix, where R(i, j) = 1 if the i-th movies was rated by the j-th user\n",
    "        \n",
    "    Returns: \n",
    "        Y (ndarray (num_movies,num_users)    : mean normalised matrix of user ratings of movies\n",
    "        mean_vec (ndarray (1, num_users)): the mean of the movies in vectorized form \n",
    "    \"\"\"\n",
    "    mean_vec = np.reshape(np.sum(Y, axis=1)/np.sum((Y != 0).astype(int), axis=1), (-1, Y.shape[0]))  #(1, nm)\n",
    "    Y -= mean_vec.T\n",
    "    Y *= R\n",
    "\n",
    "    return Y, mean_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the ratings by 443 users are already mentioned in Y, but adding our own ratings for certain movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ratings = np.zeros(Y.shape[0])\n",
    "\n",
    "\n",
    "my_ratings[2700] = 5 # Toy Story \n",
    "my_ratings[2609] = 2  #Persuasion (2007)\n",
    "my_ratings[929]  = 5   # Lord of the Rings: The Return of the King, The\n",
    "my_ratings[246]  = 5   # Shrek (2001)\n",
    "my_ratings[2716] = 3   # Inception\n",
    "my_ratings[1150] = 5   # Incredibles, The (2004)\n",
    "my_ratings[382]  = 2   # Amelie (Fabuleux destin d'Amélie Poulain, Le)\n",
    "my_ratings[366]  = 5   # Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
    "my_ratings[622]  = 5   # Harry Potter and the Chamber of Secrets (2002)\n",
    "my_ratings[988]  = 3   # Eternal Sunshine of the Spotless Mind (2004)\n",
    "my_ratings[2925] = 1   # Louis Theroux: Law & Disorder (2008)\n",
    "my_ratings[2937] = 1   # Nothing to Declare (Rien à déclarer)\n",
    "my_ratings[793]  = 5   # Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
    "\n",
    "\n",
    "#some of the ratings given by this new user, the rest of the ratings are 0 as the user has not rated them yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.c_[my_ratings, Y]\n",
    "R = np.c_[(my_ratings != 0).astype(int), R]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4778, 444)\n",
      "(4778, 444)\n"
     ]
    }
   ],
   "source": [
    "print(Y.shape)\n",
    "print(R.shape)   #new cols added \n",
    "nu += 1   #to reflect the fact that a new user was added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying mean normalisation on Y \n",
    "Y_norm, movies_mean = mean_norm(Y, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4778)\n"
     ]
    }
   ],
   "source": [
    "# print(Y_norm.shape)\n",
    "# print(Y.shape)\n",
    "print(movies_mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean values of movie ratings for each user:  [[3.4  3.25 2.   ... 3.5  3.5  3.5 ]]\n"
     ]
    }
   ],
   "source": [
    "#here since we are training to find the values for X too, we can choose the number of features as we please, hence in this \n",
    "#egs we will be using 100 features\n",
    "n = 100\n",
    "print(\"mean values of movie ratings for each user: \", movies_mean)\n",
    "\n",
    "#creating initial values of X, W, B based on this new number of features\n",
    "tf.random.set_seed(1234)  #to achieve consistency in the random nos\n",
    "X_init = tf.Variable(tf.random.normal((nm, n), dtype=tf.float64), name='X')\n",
    "W_init = tf.Variable(tf.random.normal((nu, n), dtype=tf.float64), name='W')\n",
    "B_init = tf.Variable(tf.random.normal((1, nu), dtype=tf.float64), name='B')\n",
    "\n",
    "#instantiating the Adam optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, cost: 2286455.4447972253\n",
      "epoch: 21, cost: 133685.5210945303\n",
      "epoch: 41, cost: 50539.461469094334\n",
      "epoch: 61, cost: 23852.63504154022\n",
      "epoch: 81, cost: 13176.219037940646\n",
      "epoch: 101, cost: 8200.921999031263\n",
      "epoch: 121, cost: 5614.828357320321\n",
      "epoch: 141, cost: 4173.217081024721\n",
      "epoch: 161, cost: 3331.4338394382667\n",
      "epoch: 181, cost: 2822.234005454627\n"
     ]
    }
   ],
   "source": [
    "iter = 200\n",
    "l = 1\n",
    "X, W, B = training_loop(X_init, Y_norm, W_init, B_init, R, l, iter, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.68546368 4.91422754 3.34840872 ... 3.12371376 4.03680164 3.50909084]\n",
      " [2.62247246 4.75526795 3.23976213 ... 2.85928252 3.52696279 3.51685461]\n",
      " [1.33144096 3.51508601 2.1145799  ... 1.80729587 2.13358998 2.06436881]\n",
      " ...\n",
      " [2.79787189 5.0182921  3.56858088 ... 3.32913104 3.96823924 3.6399879 ]\n",
      " [2.79829553 5.01835692 3.5695205  ... 3.32874733 3.9670432  3.63937424]\n",
      " [2.79831801 5.01835794 3.56952893 ... 3.3287716  3.96703927 3.63918386]]\n"
     ]
    }
   ],
   "source": [
    "#now to predict the ratings with our trained recommender system\n",
    "#making a prediction matrix of same order as Y(obviously)\n",
    "\n",
    "#changed X, W, B to numpy arrays by using tfarr.numpy()\n",
    "\n",
    "p = X@np.transpose(W) + B + np.transpose(movies_mean)\n",
    "print(p)   #the predictions for all users "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
