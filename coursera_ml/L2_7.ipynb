{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPLEMENTING DECISION TREES FOR CLASSIFICATION EGS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([[1,1,1],[1,0,1],[1,0,0],[1,0,0],[1,1,1],[0,1,1],[0,0,0],[1,0,1],[0,1,0],[1,0,0]])\n",
    "\n",
    "y_train = np.array([1, 1, 0, 0, 1, 1, 0, 1, 0, 0])\n",
    "\n",
    "#each col in x_train represents a feature, namely, ear shape(1: pointy, 0:floppy), face shape(1:round, 0:not), \n",
    "#whiskers(1:present, 0:absent) and the y_train represents if the sample is a cat or no where 1 is a cat\n",
    "\n",
    "m = x_train.shape[0]\n",
    "n = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the entropy func\n",
    "def entropy(p):\n",
    "    \"\"\"\n",
    "    Returns the entropy of a certain node with positive fraction p\n",
    "    \n",
    "    Args:\n",
    "        p(int): positive fraction of a node\n",
    "\n",
    "    Returns:\n",
    "        returns entropy\n",
    "    \"\"\"\n",
    "    if p ==0 or p == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return (-p*np.log2(p)-(1-p)*np.log2(1-p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting function based on a certain feature whose index is present as a param\n",
    "def splitting(x, feature_index):\n",
    "    \"\"\"\n",
    "    Returns the indices of samples which are in the left and right node of the split\n",
    "\n",
    "    Args:\n",
    "        x(ndarray (m,n)): numpy array containing the training samples of the initial node\n",
    "        feature_index (int): the index of the feature based on which the split is to be done, 0 <= feature_index <=n\n",
    "\n",
    "    Returns:\n",
    "        left_indices (list): index of the features wrt x array which are in the left node\n",
    "        right_indices (right): index of the features wrt x array which are in right node\n",
    "    \"\"\"\n",
    "\n",
    "    left_indices = []   #positive classes always go to the left node\n",
    "    right_indices = []\n",
    "    for i in range(len(x)):\n",
    "        if x[i, feature_index] == 1:\n",
    "            left_indices.append(i)\n",
    "        else:\n",
    "            right_indices.append(i)\n",
    "    return left_indices, right_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weighted sum of entropies for a layer linked to a node\n",
    "def weighed_sum(x, y, left_indices, right_indices):\n",
    "    \"\"\"\n",
    "    Returns the weighted sum of the new two nodes getting split from the initial node whose elements are x, y\n",
    "    \n",
    "    Args:\n",
    "        x(ndarray (m,n)): numpy array which is the feature set of the initial node\n",
    "        y(ndarray (m,)): target vector of the initial node\n",
    "        left_indices(list): list of indices in the new left split from the initial node wrt the original feature index\n",
    "        right_indices(list): list of indices in the new right split from the initial node wrt the original feature index\n",
    "\n",
    "    Returns:\n",
    "        weighted sum of entropy for the split\n",
    "    \"\"\"\n",
    "    w_left = len(left_indices)/len(x)\n",
    "    w_right = len(right_indices)/len(x)\n",
    "\n",
    "    if len(left_indices) != 0:\n",
    "        p_left = sum(y[left_indices])/len(left_indices)\n",
    "    else:\n",
    "        p_left = 0\n",
    "    \n",
    "    if len(right_indices) != 0:\n",
    "        p_right = sum(y[right_indices])/len(right_indices)\n",
    "    else:\n",
    "        p_right = 0\n",
    "\n",
    "    H_left = entropy(p_left)\n",
    "    H_right = entropy(p_right)\n",
    "    return (w_left*H_left + w_right*H_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding info gain of a node\n",
    "def info_gain(x, y, left_indices, right_indices):\n",
    "    \"\"\"\n",
    "    Returns the information gain of the new split from the initial node\n",
    "\n",
    "    Args:\n",
    "        x(ndarray (m,n)): numpy array which is the feature set of the initial node\n",
    "        y(ndarray (m,)): target vector of the initial node\n",
    "        left_indices(list): list of indices in the new left split from the initial node wrt the original feature index\n",
    "        right_indices(list): list of indices in the new right split from the initial node wrt the original feature index\n",
    "\n",
    "    Returns:\n",
    "        information gain of the new split\n",
    "    \"\"\"\n",
    "    w_sum = weighed_sum(x, y, left_indices, right_indices)\n",
    "    p_node = sum(y)/len(y)\n",
    "    H_node = entropy(p_node)\n",
    "\n",
    "    return H_node - w_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finding_best_split(x, y, feature_indices_list):  #feature_indices_list in this \n",
    "    #case will be [0, 1, 2]\n",
    "\n",
    "    \"\"\"\n",
    "    Returns the best feature to split a node with feature set x\n",
    "\n",
    "    Args:\n",
    "        x(ndarray (m,n)): the feature set of the node we are at currently\n",
    "        y(ndarray (m,)): the target vector of the node we are currently at\n",
    "        feature_indices_list(list): list containing the indices of the features\n",
    "\n",
    "    Returns:\n",
    "        best_feature_index (int): the index of the best feature to split that node upon\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    ig = 0\n",
    "    best_feature_index = 0\n",
    "    for i in feature_indices_list:\n",
    "        l_list, r_list = splitting(x, i)\n",
    "        ig_ = info_gain(x, y, l_list, r_list)\n",
    "        if ig_ > ig:\n",
    "            ig = ig_\n",
    "            best_feature_index = i\n",
    "    \n",
    "    return best_feature_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "best = finding_best_split(x_train, y_train, [0,1,2])\n",
    "print(best) \n",
    "#gives the index 2 indicting the root node shld split based on the \"solitary\" feature or the 3rd feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 5, 7] [2, 3, 6, 8, 9]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "l, r = splitting(x_train, best)\n",
    "print(l, r)\n",
    "print(info_gain(x_train, y_train, l, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1]\n",
      " [1 0 1]\n",
      " [1 1 1]\n",
      " [0 1 1]\n",
      " [1 0 1]]\n",
      "[0, 1, 4, 5, 7]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[l])\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4] []\n",
      "[[1 1 1]\n",
      " [1 0 1]\n",
      " [1 1 1]\n",
      " [0 1 1]\n",
      " [1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "l_, r_ = splitting(x_train[l], 2)  #when best index for feature is 2 then r list is empty\n",
    "print(l_, r_)  #these indices are now based on x_train[l] sub array\n",
    "print(x_train[l][l_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "best = finding_best_split(x_train[l], y_train[l], [0,1,2])\n",
    "print(best) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 7, 9] [5, 6, 8]\n",
      "0.034851554559677034\n"
     ]
    }
   ],
   "source": [
    "l0, r0 = splitting(x_train, 0)\n",
    "print(l0, r0)\n",
    "print(info_gain(x_train, y_train, l0, r0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 5, 8] [1, 2, 3, 6, 7, 9]\n",
      "0.12451124978365313\n"
     ]
    }
   ],
   "source": [
    "l1, r1, = splitting(x_train, 1)\n",
    "print(l1, r1)\n",
    "print(info_gain(x_train, y_train, l1, r1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[[]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DT(depth, reverse, max_depth, node_list, waiting_list, x, y, l, r):\n",
    "    while 0 <= depth < max_depth:\n",
    "        if reverse == 0:\n",
    "            depth += 1\n",
    "\n",
    "        if reverse == 0:\n",
    "            if len(l) != 0:\n",
    "                x = x_train[l]\n",
    "            else:\n",
    "                x = x_train\n",
    "            if len(r) != 0:\n",
    "                y = y_train[l]\n",
    "            else:\n",
    "                y = y_train\n",
    "        \n",
    "        # if reverse == 1:\n",
    "        #     x = x_train[r]\n",
    "\n",
    "\n",
    "        best = finding_best_split(x, y, [0,1,2])\n",
    "        l,r = splitting(x, best)\n",
    "\n",
    "        if depth != max_depth:\n",
    "            waiting_list.append(('R', depth, r))\n",
    "\n",
    "        node_list.append(('L', depth, l))\n",
    "\n",
    "        if depth == max_depth:\n",
    "            node_list.append(('R', depth, r))\n",
    "\n",
    "        # ig = info_gain(x, y, l, r)\n",
    "        # if ig <= 0.03:\n",
    "        #     break\n",
    "\n",
    "        # if reverse == 0:\n",
    "        #     x = x_train[l]\n",
    "        #     y = y_train[l]\n",
    "\n",
    "\n",
    "        # if depth == 3:\n",
    "        #     reverse = 1\n",
    "        #     depth -= 1\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('L', 1, [0, 1, 4, 5, 7]), ('L', 2, [0, 1, 2, 4]), ('L', 3, [0, 1, 3]), ('R', 3, [2])]\n",
      "[('R', 1, [2, 3, 6, 8, 9]), ('R', 2, [3])]\n"
     ]
    }
   ],
   "source": [
    "depth = 0\n",
    "waiting_list = []\n",
    "node_list = []\n",
    "feature_indices_list = [0,1,2]\n",
    "x = x_train\n",
    "y = y_train\n",
    "reverse = 0\n",
    "l = []\n",
    "r = []\n",
    "\n",
    "DT(depth, reverse, 3, node_list, waiting_list, x, y, l, r)\n",
    "print(node_list)\n",
    "print(waiting_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#applying splits for right node of first split\n",
    "depth_ = 0\n",
    "node_list_ = []\n",
    "waiting_list_ = []\n",
    "l_ = []\n",
    "r_ = []\n",
    "x_ = x_train[waiting_list[0][2]]\n",
    "y_ = y_train[waiting_list[0][2]]\n",
    "print(y_)\n",
    "#DT(depth_, reverse, 3, node_list_, waiting_list_, x_train[waiting_list[0][2]], y_train[waiting_list[0][2]], l_, r_)\n",
    "print(node_list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
